/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ (() => {

eval("const div = document.createElement('div');\r\ndocument.body.appendChild(div);\r\n\r\nconst bias = document.createElement('input');\r\nbias.type = 'range';\r\nbias.id = 'bias';\r\nbias.min = 0.00000000000000000000000000005;\r\nbias.max = 1.0;\r\nbias.step = 0.00000000000000000000000000005;\r\ndiv.appendChild(bias);\r\ndiv.appendChild(document.createElement('div'));\r\n\r\nconst canvas = document.createElement('canvas');\r\ncanvas.width = 1200;\r\ncanvas.height = 1200;\r\ncanvas.id = 'nft-canvas';\r\ndiv.appendChild(canvas);\r\n\r\ndocument.title = \"NFT!\";\r\n\r\nconst gl = canvas.getContext('experimental-webgl');\r\n\r\nconst vertexSource = `\r\n    precision highp float;\r\n\r\n    attribute vec2 a_pos;\r\n\r\n    varying vec2 uv;\r\n\r\n    void main() {\r\n        uv = a_pos;\r\n        uv.y = 1.0 - uv.y;\r\n        vec4 pos = vec4(a_pos * 2.0 - 1.0, 0.0, 1.0);\r\n        gl_Position = pos;\r\n    }`;\r\n\r\nconst fragmentSource = `\r\n    precision highp float;\r\n\r\n    uniform sampler2D u_textures[5];\r\n\r\n    varying vec2 uv;\r\n\r\n    vec3 screen(vec3 v1, vec3 v2) {\r\n        return (vec3(1.0) - v2) * v1 + v2;\r\n    }\r\n\r\n    uniform float bias;\r\n\r\n    void main() {\r\n        vec4 color0 = texture2D(u_textures[0], uv);\r\n        vec4 color1 = texture2D(u_textures[1], uv);\r\n        vec4 color2 = texture2D(u_textures[2], uv);\r\n        vec4 color3 = texture2D(u_textures[3], uv);\r\n        float alpha = texture2D(u_textures[4], uv).r;\r\n        \r\n        gl_FragColor = vec4(mix(screen(screen(color0.rgb, color1.rgb), color2.rgb), color3.rgb, alpha), 1.0);\r\n    }`;\r\n\r\nconst vertexShader = gl.createShader(gl.VERTEX_SHADER);\r\nvertexShader && gl.shaderSource(vertexShader, vertexSource);\r\nvertexShader && gl.compileShader(vertexShader);\r\nif (vertexShader && !gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {\r\n    alert(gl.getShaderInfoLog(vertexShader));\r\n}\r\n\r\nconst fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);\r\nfragmentShader && gl.shaderSource(fragmentShader, fragmentSource);\r\nfragmentShader && gl.compileShader(fragmentShader);\r\nif (fragmentShader && !gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {\r\n    alert(gl.getShaderInfoLog(fragmentShader));\r\n}\r\n\r\nconst program = gl.createProgram();\r\nif (program) {\r\n    vertexShader && gl.attachShader(program, vertexShader);\r\n    fragmentShader && gl.attachShader(program, fragmentShader);\r\n    gl.linkProgram(program);\r\n}\r\n\r\nconst quadBuffer = gl.createBuffer();\r\ngl.bindBuffer(gl.ARRAY_BUFFER, quadBuffer);\r\nconst buffer = new Float32Array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]);\r\ngl.bufferData(gl.ARRAY_BUFFER, buffer, gl.DYNAMIC_DRAW);\r\n\r\nfunction setupVideo(url, isReady, index) {\r\n    const video = document.createElement('video');\r\n\r\n    var playing = false;\r\n    var timeupdate = false;\r\n\r\n    video.autoplay = true;\r\n    video.muted = true;\r\n    video.loop = true;\r\n\r\n    video.addEventListener('playing', function() {\r\n        playing = true;\r\n        checkReady();\r\n    }, true);\r\n\r\n    video.addEventListener('timeupdate', function() {\r\n        timeupdate = true;\r\n        checkReady();\r\n    }, true);\r\n\r\n    video.src = url;\r\n    video.play();\r\n\r\n    function checkReady() {\r\n        if (playing && timeupdate) {\r\n            isReady[index] = true;\r\n        }\r\n    }\r\n\r\n    return video;\r\n}\r\n\r\nfunction loadTexture (gl, url = undefined) {\r\n    const texture = gl.createTexture();\r\n    gl.bindTexture(gl.TEXTURE_2D, texture);\r\n\r\n    const level = 0;\r\n    const internalFormat = gl.RGBA;\r\n    const width = 1;\r\n    const height = 1;\r\n    const border = 0;\r\n    const srcFormat = gl.RGBA;\r\n    const srcType = gl.UNSIGNED_BYTE;\r\n    const pixel = new Uint8Array([0, 0, 0, 255]);\r\n    gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,\r\n                    width, height, border, srcFormat, srcType,\r\n                    pixel);\r\n    \r\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\r\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\r\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\r\n\r\n    if (url) {\r\n        const image = new Image();\r\n        image.crossOrigin = 'anonymous';\r\n        image.onload = function() {\r\n            gl.bindTexture(gl.TEXTURE_2D, texture);\r\n            gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,\r\n                        srcFormat, srcType, image);\r\n        };\r\n        image.onerror = (e) => {console.log('e')}\r\n        image.src = url;  \r\n    }\r\n\r\n    return texture;\r\n}\r\n\r\nfunction updateTexture(gl, texture, video) {\r\n    const level = 0;\r\n    const internalFormat = gl.RGBA;\r\n    const srcFormat = gl.RGBA;\r\n    const srcType = gl.UNSIGNED_BYTE;\r\n    gl.bindTexture(gl.TEXTURE_2D, texture);\r\n    gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,\r\n                  srcFormat, srcType, video);\r\n  }\r\n  \r\n\r\nconst videos = [undefined, undefined, undefined, undefined, undefined];\r\nconst isReady = [false, false, false, false, false];\r\nvideos[0] = setupVideo('./assets/videos/Body_Noise.mp4', isReady, 0);\r\nvideos[1] = setupVideo('./assets/videos/Background_1.mp4', isReady, 1);\r\nvideos[2] = setupVideo('./assets/videos/Fireball_3.mp4', isReady, 2);\r\nvideos[3] = setupVideo('./assets/videos/Head_001.mp4', isReady, 3);\r\nvideos[4] = setupVideo('./assets/videos/amaskHead_001.mp4', isReady, 4);\r\nconst textures = [];\r\ntextures.push(loadTexture(gl));\r\ntextures.push(loadTexture(gl));\r\ntextures.push(loadTexture(gl));\r\ntextures.push(loadTexture(gl));\r\ntextures.push(loadTexture(gl));\r\n\r\nconst render = () => {\r\n    gl.disable(gl.DEPTH_TEST);\r\n    gl.useProgram(program);\r\n\r\n    gl.uniform1f(gl.getUniformLocation(program, 'bias'), bias.value);\r\n    \r\n    gl.bindBuffer(gl.ARRAY_BUFFER, quadBuffer);\r\n    gl.enableVertexAttribArray(gl.getAttribLocation(program, 'a_pos'));\r\n    gl.vertexAttribPointer(gl.getAttribLocation(program, 'a_pos'), 2, gl.FLOAT, false, 0, 0);\r\n    gl.enable(gl.BLEND);\r\n    gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);\r\n\r\n    for (let i = 0; i < 5; i++) {\r\n        gl.uniform1i(gl.getUniformLocation(program, 'u_textures[' + i + ']'), i);\r\n        gl.activeTexture(gl.TEXTURE0 + i);\r\n        gl.bindTexture(gl.TEXTURE_2D, textures[i]);\r\n        if (isReady[i]) {\r\n            updateTexture(gl, textures[i], videos[i]);\r\n        }\r\n    }\r\n\r\n    gl.drawArrays(gl.TRIANGLES, 0, 6);\r\n}\r\n\r\nsetInterval(() => {\r\n    render();\r\n}, 1000 / 25);\n\n//# sourceURL=webpack://nft-viewer/./src/index.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = {};
/******/ 	__webpack_modules__["./src/index.js"]();
/******/ 	
/******/ })()
;